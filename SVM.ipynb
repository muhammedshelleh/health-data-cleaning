{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "provenance": [],
      "mount_file_id": "1biigMAYeLKMYcKzTz1YBjd1cR22G22Wt",
      "authorship_tag": "ABX9TyPoWELyCWG3AFw+/GUkQr28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammedshelleh/health-data-cleaning/blob/master/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGsvFltbwUxK"
      },
      "source": [
        "# svm.py\r\n",
        "import numpy as np  # for handling multi-dimensional array operation\r\n",
        "import pandas as pd  # for reading data from csv \r\n",
        "import statsmodels.api as sm  # for finding the p-value\r\n",
        "from sklearn.preprocessing import MinMaxScaler  # for normalization\r\n",
        "from sklearn.model_selection import train_test_split as tts\r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LZw5LOjzg3H"
      },
      "source": [
        "def CompletenessRatio(data):\r\n",
        "    completeness_ratio = []\r\n",
        "    for column in data.columns:\r\n",
        "        ratio =  data[column].describe()[0] / data[column].size\r\n",
        "        completeness_ratio.append(ratio)\r\n",
        "    return completeness_ratio"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWTwJy7zirC"
      },
      "source": [
        "def InCompletenessRatio(data):\r\n",
        "    completeness_ratio = []\r\n",
        "    for column in data.columns:\r\n",
        "        ratio = 1-  data[column].describe()[0] / data[column].size \r\n",
        "        completeness_ratio.append(ratio)\r\n",
        "    return completeness_ratio"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW9CBhjzzlpM"
      },
      "source": [
        "def get_best_dist(completeness_column_wise_data):\r\n",
        "    # # Distribution Fitting using SciPy\r\n",
        "    # ##  Above cell show that the best distribution that the data could be fit to is alpha\r\n",
        "    dist_results = []\r\n",
        "    for i in dists:\r\n",
        "        dist = getattr(stats, i)\r\n",
        "        param = dist.fit(completeness_column_wise_data)\r\n",
        "        a = stats.kstest(completeness_column_wise_data, i, args=param)\r\n",
        "        dist_results.append((i, a[0], a[1]))\r\n",
        "    dist_results.sort(key=lambda x: float(x[2]), reverse=True)\r\n",
        "    for j in dist_results:\r\n",
        "        print(\"{}: statistic={}, pvalue={}\".format(j[0], j[1], j[2]))\r\n",
        "    return dist_results[0][0]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIAJ0nhSzmKa"
      },
      "source": [
        "def distribution_fitting(sample):\r\n",
        "    results_1 = []\r\n",
        "    for i in dists:\r\n",
        "        dist = getattr(stats, i)\r\n",
        "        param = dist.fit(sample)\r\n",
        "        a = stats.kstest(sample, i, args=param)\r\n",
        "        results_1.append((i,a[0],a[1]))\r\n",
        "\r\n",
        "\r\n",
        "    results_1.sort(key=lambda x:float(x[2]), reverse=True)\r\n",
        "    for j in results_1:\r\n",
        "        print(\"{}: statistic={}, pvalue={}\".format(j[0], j[1], j[2]))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhLog1dDzpYf"
      },
      "source": [
        "def get_fitted_points(input_data):\r\n",
        "    best_dist = 'foldcauchy'\r\n",
        "    print(\"Best dist: \", best_dist)\r\n",
        "    dist = getattr(stats, best_dist)\r\n",
        "    param = dist.fit(input_data)\r\n",
        "\r\n",
        "    x = input_data\r\n",
        "    y = stats.foldcauchy.pdf(x, *param)\r\n",
        "    return x, y"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9SUJ8fqxqxp"
      },
      "source": [
        "# >> FEATURE SELECTION << #\r\n",
        "def remove_correlated_features(X):\r\n",
        "  def remove_less_significant_features(X, Y):\r\n",
        "# >> MODEL TRAINING << #\r\n",
        "    def compute_cost(W, X, Y):\r\n",
        "      def calculate_cost_gradient(W, X_batch, Y_batch):\r\n",
        "        def sgd(features, outputs):\r\n",
        "          def init():\r\n",
        "              n_bins = 10\r\n",
        "              data = pd.read_csv('NNDSS_-_TABLE_1FF._Severe_acute_respiratory_syndrome-associated_coronavirus_disease_to_Shigellosis.csv')\r\n",
        "              completeness_column_wise = CompletenessRatio(data)\r\n",
        "              # SVM only accepts numerical values. \r\n",
        "              # Therefore, we will transform the categories M and B into\r\n",
        "              # values 1 and -1 (or -1 and 1), respectively.\r\n",
        "              diagnosis_map = {'NaN':0, '1':1}\r\n",
        "              data['Shigellosis, Current week'] = data['Shigellosis, Current week'].map(diagnosis_map)\r\n",
        "              # drop last column (extra column added by pd)\r\n",
        "              # and unnecessary first column (id)\r\n",
        "              data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\r\n",
        "              Y = data.loc[:, 'Shigellosis, Current week']  # all rows of 'diagnosis' \r\n",
        "              X = data.iloc[:, 1:]  # all rows of column 1 and ahead (features)\r\n",
        "              # normalize the features using MinMaxScalar from\r\n",
        "              # sklearn.preprocessing\r\n",
        "              X_normalized = MinMaxScaler().fit_transform(X.values)\r\n",
        "              X = pd.DataFrame(X_normalized)\r\n",
        "              # first insert 1 in every row for intercept b\r\n",
        "              X.insert(loc=len(X.columns), column='intercept', value=1)\r\n",
        "              # test_size is the portion of data that will go into test set\r\n",
        "              # random_state is the seed used by the random number generator\r\n",
        "              print(\"splitting dataset into train and test sets...\")\r\n",
        "              X_train, X_test, y_train, y_test = tts(X, Y, test_size=0.2, random_state=42)\r\n",
        "              print(\"training started...\")\r\n",
        "              W = sgd(X_train.to_numpy(), y_train.to_numpy())\r\n",
        "              print(\"training finished.\")\r\n",
        "              print(\"weights are: {}\".format(W))\r\n",
        "              # testing the model on test set\r\n",
        "              y_test_predicted = np.array([])\r\n",
        "              for i in range(X_test.shape[0]):\r\n",
        "                  yp = np.sign(np.dot(W, X_test.to_numpy()[i])) #model\r\n",
        "                  y_test_predicted = np.append(y_test_predicted, yp)\r\n",
        "              print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test.to_numpy(), y_test_predicted)))\r\n",
        "              print(\"recall on test dataset: {}\".format(recall_score(y_test.to_numpy(), y_test_predicted)))\r\n",
        "              print(\"precision on test dataset: {}\".format(recall_score(y_test.to_numpy(), y_test_predicted)))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "YKKEYOMgwXGS",
        "outputId": "8fd32e3d-f968-41ed-9c08-5329bd7a9cfe"
      },
      "source": [
        "df = pd.read_csv('NNDSS_-_TABLE_1FF._Severe_acute_respiratory_syndrome-associated_coronavirus_disease_to_Shigellosis.csv')\r\n",
        "df.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reporting Area</th>\n",
              "      <th>MMWR Year</th>\n",
              "      <th>MMWR Week</th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Current week</th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Current week, flag</th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Previous 52 weeks Maxâ€ </th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Previous 52 weeks Maxâ€ , flag</th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Cum 2021â€ </th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Cum 2021â€ , flag</th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Cum 2020â€ </th>\n",
              "      <th>Severe acute respiratory syndrome-associated coronavirus desease, Cum 2020â€ , flag</th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Current week</th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Current week, flag</th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Previous 52 weeks Maxâ€ </th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Previous 52 weeks Maxâ€ , flag</th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Cum 2021â€ </th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Cum 2021â€ , flag</th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Cum 2020â€ </th>\n",
              "      <th>Shiga toxin-producing Escherichia coli(STEC), Cum 2020â€ , flag</th>\n",
              "      <th>Shigellosis, Current week</th>\n",
              "      <th>Shigellosis, Current week, flag</th>\n",
              "      <th>Shigellosis, Previous 52 weeks Maxâ€ </th>\n",
              "      <th>Shigellosis, Previous 52 weeks Maxâ€ , flag</th>\n",
              "      <th>Shigellosis, Cum 2021â€ </th>\n",
              "      <th>Shigellosis, Cum 2021â€ , flag</th>\n",
              "      <th>Shigellosis, Cum 2020â€ </th>\n",
              "      <th>Shigellosis, Cum 2020â€ , flag</th>\n",
              "      <th>Location 1</th>\n",
              "      <th>Location 2</th>\n",
              "      <th>Reporting Area Sort</th>\n",
              "      <th>geocode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TOTAL</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>221</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>161.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>336</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>231.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TOTAL</td>\n",
              "      <td>20210170</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US RESIDENTS</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>221</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>161.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>336</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>231.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US RESIDENTS</td>\n",
              "      <td>20210101</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEW HAMPSHIRE</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NEW HAMPSHIRE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20210106</td>\n",
              "      <td>POINT (-71.57139 43.680429)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20210111</td>\n",
              "      <td>POINT (-75.59655 42.921241)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PACIFIC</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>56.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>84</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PACIFIC</td>\n",
              "      <td>20210157</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Reporting Area  MMWR Year  ...  Reporting Area Sort                      geocode\n",
              "0          TOTAL       2021  ...             20210170                          NaN\n",
              "1   US RESIDENTS       2021  ...             20210101                          NaN\n",
              "2  NEW HAMPSHIRE       2021  ...             20210106  POINT (-71.57139 43.680429)\n",
              "3       NEW YORK       2021  ...             20210111  POINT (-75.59655 42.921241)\n",
              "4        PACIFIC       2021  ...             20210157                          NaN\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn1hMooJwhLv"
      },
      "source": [
        "def compute_cost(W, X, Y):\r\n",
        "    # calculate hinge loss\r\n",
        "    N = X.shape[0]\r\n",
        "    distances = 1 - Y * (np.dot(X, W))\r\n",
        "    distances[distances < 0] = 0  # equivalent to max(0, distance)\r\n",
        "    hinge_loss = reg_strength * (np.sum(distances) / N)\r\n",
        "    \r\n",
        "    # calculate cost\r\n",
        "    cost = 1 / 2 * np.dot(W, W) + hinge_loss\r\n",
        "    return cost"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwaEuTsUyv1Q"
      },
      "source": [
        "def calculate_cost_gradient(W, X_batch, Y_batch):\r\n",
        "    # if only one example is passed (eg. in case of SGD)\r\n",
        "    if type(Y_batch) == np.float64:\r\n",
        "        Y_batch = np.array([Y_batch])\r\n",
        "        X_batch = np.array([X_batch])\r\n",
        "    distance = 1 - (Y_batch * np.dot(X_batch, W))\r\n",
        "    dw = np.zeros(len(W))\r\n",
        "    for ind, d in enumerate(distance):\r\n",
        "        if max(0, d) == 0:\r\n",
        "            di = W\r\n",
        "        else:\r\n",
        "            di = W - (reg_strength * Y_batch[ind] * X_batch[ind])\r\n",
        "        dw += di\r\n",
        "    dw = dw/len(Y_batch)  # average\r\n",
        "    return dw"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5N72hgay0MN"
      },
      "source": [
        "def sgd(features, outputs):\r\n",
        "    max_epochs = 5000\r\n",
        "    weights = np.zeros(features.shape[1])\r\n",
        "    # stochastic gradient descent\r\n",
        "    for epoch in range(1, max_epochs): \r\n",
        "        # shuffle to prevent repeating update cycles\r\n",
        "        X, Y = shuffle(features, outputs)\r\n",
        "        for ind, x in enumerate(X):\r\n",
        "            ascent = calculate_cost_gradient(weights, x, Y[ind])\r\n",
        "            weights = weights - (learning_rate * ascent)\r\n",
        "            \r\n",
        "    return weights"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JKakDB5y1gD"
      },
      "source": [
        "def sgd(features, outputs):\r\n",
        "    max_epochs = 5000\r\n",
        "    weights = np.zeros(features.shape[1])\r\n",
        "    nth = 0\r\n",
        "    prev_cost = float(\"inf\")\r\n",
        "    cost_threshold = 0.01  # in percent\r\n",
        "    # stochastic gradient descent\r\n",
        "    for epoch in range(1, max_epochs):\r\n",
        "        # shuffle to prevent repeating update cycles\r\n",
        "        X, Y = shuffle(features, outputs)\r\n",
        "        for ind, x in enumerate(X):\r\n",
        "            ascent = calculate_cost_gradient(weights, x, Y[ind])\r\n",
        "            weights = weights - (learning_rate * ascent)\r\n",
        "        # convergence check on 2^nth epoch\r\n",
        "        if epoch == 2 ** nth or epoch == max_epochs - 1:\r\n",
        "            cost = compute_cost(weights, features, outputs)\r\n",
        "            print(\"Epoch is:{} and Cost is: {}\".format(epoch, cost))\r\n",
        "            # stoppage criterion\r\n",
        "            if abs(prev_cost - cost) < cost_threshold * prev_cost:\r\n",
        "                return weights\r\n",
        "            prev_cost = cost\r\n",
        "            nth += 1\r\n",
        "    return weights"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "id": "HiNnBLL3zPGi",
        "outputId": "fb8d5164-0aba-40bd-e97f-1dfb95f1b2fd"
      },
      "source": [
        "# set hyper-parameters and call init\r\n",
        "# hyper-parameters are normally tuned using cross-validation\r\n",
        "# but following work good enough\r\n",
        "reg_strength = 10000 # regularization strength\r\n",
        "learning_rate = 0.000001\r\n",
        "init()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'diagnosis'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-d7e9e8774b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreg_strength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;31m# regularization strength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.000001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-62036a7d38b0>\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# values 1 and -1 (or -1 and 1), respectively.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdiagnosis_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagnosis_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# drop last column (extra column added by pd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# and unnecessary first column (id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'diagnosis'"
          ]
        }
      ]
    }
  ]
}